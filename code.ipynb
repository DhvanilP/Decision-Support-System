{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decison Support System\n",
    "### Deciding Factors\n",
    "- Longevity: time since review\n",
    "- Length of title and text: count the number of words\n",
    "- Helpfulness of a review: ratio of “helpful votes” to “total votes”\n",
    "- Readership: total number of votes of a review\n",
    "- Select products wtih atleast 100 reviews, eliminated the reviews that had less than 4 votes\n",
    "- Polarity = positive sentiment + negative sentiment\n",
    "- Sentiment = positive sentiment - negative sentiment - 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip \n",
    "import json\n",
    "import shutil\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc3 as pm\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getSentimentsAndLengthFromFile(nameOfFile):\n",
    "    df=pd.DataFrame()\n",
    "    file = open(nameOfFile, encoding = \"utf8\")\n",
    "    count = 0\n",
    "    column_names = []\n",
    "    for line in file:\n",
    "        count=count+1\n",
    "        if count is 1:\n",
    "            column_names = line.split('\\t')\n",
    "            df=pd.DataFrame(columns = column_names)\n",
    "        temp_line = line.rstrip().split('\\t')\n",
    "        df = df.append(pd.Series(temp_line ,index = column_names), ignore_index = True)\n",
    "    file.close()\n",
    "    return df\n",
    "\n",
    "def unzipJson(filename, saveas):\n",
    "    \"both arguments are strings\"\n",
    "    with gzip.open(filename, 'rb') as f_in:\n",
    "        with open(saveas, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "            \n",
    "def getDataFromJsonFile(filename, noOfRev):\n",
    "    count = 0\n",
    "    df = pd.DataFrame()\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            if count == noOfRev:\n",
    "                break\n",
    "            count = count + 1\n",
    "            if count%500==0:\n",
    "                print(count)\n",
    "            data = json.loads(line)\n",
    "            dictionary=json.loads(line)\n",
    "            dictionary[\"helpful\"] = str(dictionary[\"helpful\"][0])+\":\"+str(dictionary[\"helpful\"][1])\n",
    "            df = df.append(pd.DataFrame(dictionary,index = [count]), sort = False)\n",
    "    return df\n",
    "\n",
    "def plot_traces(trcs, varnames=None):\n",
    "    '''Plot traces with overlaid means and values'''\n",
    "    nrows = len(trcs.varnames)\n",
    "    if varnames is not None:\n",
    "        nrows = len(varnames)\n",
    "\n",
    "    ax = pm.traceplot(trcs, varnames=varnames, figsize=(12,nrows*1.4),\n",
    "                      lines={k: v['mean'] for k, v in\n",
    "                             pm.summary(trcs,varnames=varnames).iterrows()})\n",
    "\n",
    "    for i, mn in enumerate(pm.summary(trcs, varnames=varnames)['mean']):\n",
    "        ax[i,0].annotate('{:.2f}'.format(mn), xy=(mn,0), xycoords='data',\n",
    "                         xytext=(5,10), textcoords='offset points', rotation=90,\n",
    "                         va='bottom', fontsize='large', color='#AA0022')\n",
    "\n",
    "def strip_derived_rvs(rvs):\n",
    "    '''Remove PyMC3-generated RVs from a list'''\n",
    "    ret_rvs = []\n",
    "    for rv in rvs:\n",
    "        if not (re.search('_log',rv.name) or re.search('_interval',rv.name)):\n",
    "            ret_rvs.append(rv)\n",
    "    return ret_rvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description of the below cell\n",
    "- unzip the json.gz file \n",
    "- get a dataFrame consisting of 35000 reviews\n",
    "- store this dataFrame in a csv file\n",
    "- now this csv file is converted to a txt file that is then\n",
    "    analysed using the sentistrength software, resulting is a\n",
    "    txt file having analysed result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzipJson(\"reviews_Electronics_5.json.gz\",\"reviews_Electronics_5.json\")\n",
    "# df = getDataFromJsonFile(\"reviews_Electronics_5.json\",35000)\n",
    "# df.to_csv(\"dataset_electronic.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description of the below cell\n",
    "- dataset_analysed.txt contains all the analysed data that is converted to a dataFrame\n",
    "- dataFrame is stored in a csv file for faster access next time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = getSentimentsAndLengthFromFile(\"dataset_analysed.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.drop(0,0)\n",
    "# data.to_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['polarityText'] = data['reviewTextPositive'] + data['reviewTextNegative']\n",
    "# data['polaritySummary'] = data['summaryPositive'] + data['summaryNegative\\n']\n",
    "# data['sentimentText'] = data['reviewTextPositive'] - data['reviewTextNegative']-2\n",
    "# data['sentimentSummary'] = data['summaryPositive'] - data['summaryNegative\\n'] - 2\n",
    "# data['summaryLength'] = data['summary'].str.split().str.len()\n",
    "# data['reviewTextLength'] = data['reviewText'].str.split().str.len()\n",
    "# data['readership'] = data['helpful'].str.split(':').str[1]\n",
    "# data['longetivity'] = time.time() - data['unixReviewTime']\n",
    "# del data['no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset\n",
    "data = pd.read_csv('dataset.csv',index_col=0)\n",
    "data['helpful_votes'] = data['helpful'].str.split(':').str[0]\n",
    "data['helpful_votes'] = data.helpful_votes.astype(float)\n",
    "data['longetivity'] = data['longetivity']//86400\n",
    "# data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select products wtih atleast 100 reviews, eliminated the reviews that had less than 4 votes\n",
    "tempDf = data.groupby('asin').size().rename(\"countOfReviews\").reset_index()\n",
    "data = data.merge(tempDf)\n",
    "data = data[data['countOfReviews'] >= 100]\n",
    "data = data.loc[data['readership'] >= 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1Df = pd.DataFrame(columns=['range', 'median', 'mean', 'SD'], \n",
    "                        index = ['Rating', 'Longetivity', 'Total Votes', 'Helpful votes', 'Title sentiment',\n",
    "                                 'Title polarity', 'Review sentiment', 'Review polarity', 'Title length', 'Review length'])\n",
    "\n",
    "table1Df.loc['Rating'] = pd.Series({\n",
    "    'range' : str(data['overall'].min())+'-'+str(data['overall'].max()),\n",
    "    'median' : data['overall'].median(),\n",
    "    'mean' : data['overall'].mean(),\n",
    "    'SD' : data['overall'].std()\n",
    "})\n",
    "table1Df.loc['Longetivity'] = pd.Series({\n",
    "    'range' : str(data['longetivity'].min())+'-'+str(data['longetivity'].max()),\n",
    "    'median' : data['longetivity'].median(),\n",
    "    'mean' : data['longetivity'].mean(),\n",
    "    'SD' : data['longetivity'].std()\n",
    "})\n",
    "table1Df.loc['Total Votes'] = pd.Series({\n",
    "    'range' : str(data['readership'].min())+'-'+str(data['readership'].max()),\n",
    "    'median' : data['readership'].median(),\n",
    "    'mean' : data['readership'].mean(),\n",
    "    'SD' : data['readership'].std()\n",
    "})\n",
    "table1Df.loc['Helpful votes'] = pd.Series({\n",
    "    'range' : str(data['helpful_votes'].min())+'-'+str(data['helpful_votes'].max()),\n",
    "    'median' : data['helpful_votes'].median(),\n",
    "    'mean' : data['helpful_votes'].mean(),\n",
    "    'SD' : data['helpful_votes'].std()\n",
    "})\n",
    "table1Df.loc['Title sentiment'] = pd.Series({\n",
    "    'range' : str(data['sentimentSummary'].min())+'-'+str(data['sentimentSummary'].max()),\n",
    "    'median' : data['sentimentSummary'].median(),\n",
    "    'mean' : data['sentimentSummary'].mean(),\n",
    "    'SD' : data['sentimentSummary'].std()\n",
    "})\n",
    "table1Df.loc['Title polarity'] = pd.Series({\n",
    "    'range' : str(data['polaritySummary'].min())+'-'+str(data['polaritySummary'].max()),\n",
    "    'median' : data['polaritySummary'].median(),\n",
    "    'mean' : data['polaritySummary'].mean(),\n",
    "    'SD' : data['polaritySummary'].std()\n",
    "})\n",
    "table1Df.loc['Review sentiment'] = pd.Series({\n",
    "    'range' : str(data['sentimentText'].min())+'-'+str(data['sentimentText'].max()),\n",
    "    'median' : data['sentimentText'].median(),\n",
    "    'mean' : data['sentimentText'].mean(),\n",
    "    'SD' : data['sentimentText'].std()\n",
    "})\n",
    "table1Df.loc['Review polarity'] = pd.Series({\n",
    "    'range' : str(data['polarityText'].min())+'-'+str(data['polarityText'].max()),\n",
    "    'median' : data['polarityText'].median(),\n",
    "    'mean' : data['polarityText'].mean(),\n",
    "    'SD' : data['polarityText'].std()\n",
    "})\n",
    "table1Df.loc['Title length'] = pd.Series({\n",
    "    'range' : str(data['summaryLength'].min())+'-'+str(data['summaryLength'].max()),\n",
    "    'median' : data['summaryLength'].median(),\n",
    "    'mean' : data['summaryLength'].mean(),\n",
    "    'SD' : data['summaryLength'].std()\n",
    "})\n",
    "table1Df.loc['Review length'] = pd.Series({\n",
    "    'range' : str(data['reviewTextLength'].min())+'-'+str(data['reviewTextLength'].max()),\n",
    "    'median' : data['reviewTextLength'].median(),\n",
    "    'mean' : data['reviewTextLength'].mean(),\n",
    "    'SD' : data['reviewTextLength'].std()\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formula\n",
    "- log(Total Votes) = B0 + B1 * Title_Sentiment + B2 * TITLE_POSTIVE + B3 * Title_length + B4 * Title_Sentiment * TITLE_POSTIVE + B5 * log(Review_Length) + B6 * log(Longevity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>range</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>SD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rating</th>\n",
       "      <td>1.0-5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.75608</td>\n",
       "      <td>1.50318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Longetivity</th>\n",
       "      <td>1710.0-6887.0</td>\n",
       "      <td>4082</td>\n",
       "      <td>4033.06</td>\n",
       "      <td>1169.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Votes</th>\n",
       "      <td>4-1591</td>\n",
       "      <td>7</td>\n",
       "      <td>24.1913</td>\n",
       "      <td>69.5943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Helpful votes</th>\n",
       "      <td>0.0-1556.0</td>\n",
       "      <td>6</td>\n",
       "      <td>20.6897</td>\n",
       "      <td>66.8541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title sentiment</th>\n",
       "      <td>0-5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.11111</td>\n",
       "      <td>1.0663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title polarity</th>\n",
       "      <td>-4-4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.578567</td>\n",
       "      <td>1.24204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Review sentiment</th>\n",
       "      <td>0-8</td>\n",
       "      <td>3</td>\n",
       "      <td>3.17094</td>\n",
       "      <td>1.44084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Review polarity</th>\n",
       "      <td>-3-4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.350427</td>\n",
       "      <td>1.15912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title length</th>\n",
       "      <td>1-23</td>\n",
       "      <td>5</td>\n",
       "      <td>5.1716</td>\n",
       "      <td>2.85392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Review length</th>\n",
       "      <td>9.0-2079.0</td>\n",
       "      <td>121</td>\n",
       "      <td>176.77</td>\n",
       "      <td>178.095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          range median      mean       SD\n",
       "Rating                  1.0-5.0      4   3.75608  1.50318\n",
       "Longetivity       1710.0-6887.0   4082   4033.06  1169.66\n",
       "Total Votes              4-1591      7   24.1913  69.5943\n",
       "Helpful votes        0.0-1556.0      6   20.6897  66.8541\n",
       "Title sentiment             0-5      1   1.11111   1.0663\n",
       "Title polarity             -4-4      0  0.578567  1.24204\n",
       "Review sentiment            0-8      3   3.17094  1.44084\n",
       "Review polarity            -3-4      0  0.350427  1.15912\n",
       "Title length               1-23      5    5.1716  2.85392\n",
       "Review length        9.0-2079.0    121    176.77  178.095"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n",
    "table1Df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "readerData = pd.DataFrame()\n",
    "readerData['Title_Sentiment'] = data['sentimentSummary']\n",
    "readerData['TITLE_POSITIVE'] = data['polaritySummary']\n",
    "readerData.loc[readerData['TITLE_POSITIVE'] > 0,'temp'] = 1\n",
    "readerData.loc[readerData['TITLE_POSITIVE'] <= 0,'temp'] = 0\n",
    "readerData['TITLE_POSITIVE'] = readerData['temp']\n",
    "del readerData['temp']\n",
    "readerData['Title_Length'] = data['summaryLength']\n",
    "readerData['B4_mul'] = readerData['Title_Sentiment'] * readerData['TITLE_POSITIVE']\n",
    "readerData['B5_mul'] = np.log(data['reviewTextLength'])\n",
    "readerData['B6_mul'] = np.log(data['longetivity'])\n",
    "readerData['TITLE_POSITIVE'] = data['summaryPositive']\n",
    "logTotalVotes = np.log10(data['readership'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-e8f0e2c88a1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreg_for_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreaderData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogTotalVotes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0;32m   1216\u001b[0m                          order=\"C\")\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    170\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[0;32m    171\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "reg_for_reader = LinearRegression().fit(readerData, logTotalVotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.26033213e-02,  2.67401674e-01, -4.15890052e-03,\n",
       "        -1.80343651e-01, -7.40672283e-03,  5.07794216e-01,\n",
       "        -8.80496418e+00],\n",
       "       [ 1.20786956e-01, -6.24836103e-01,  1.09204385e-02,\n",
       "         4.80812012e-01, -8.17379698e-02, -1.35458932e-01,\n",
       "         3.60933763e+00],\n",
       "       [-1.64783625e-01,  1.70151337e-01, -5.22246043e-02,\n",
       "        -1.87758590e-02, -3.33029802e-02, -1.25757926e+00,\n",
       "         6.38282610e+00],\n",
       "       [ 5.18105306e-02, -5.94190845e-01,  2.80760752e-01,\n",
       "        -3.21534830e-01,  1.05274718e-01, -1.23985458e+00,\n",
       "         1.57360590e+00]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readerData['logTotalVotes'] = logTotalVotes\n",
    "reg_for_reader.coef_\n",
    "# reg_for_reader.intercept_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpful = pd.DataFrame()\n",
    "helpful['Review_Sentiment'] = data['sentimentText']\n",
    "helpful['REVIEW_NEUTRAL'] = data['polarityText']\n",
    "helpful.loc[helpful['REVIEW_NEUTRAL'] == 0,'temp'] = 1\n",
    "helpful.loc[helpful['REVIEW_NEUTRAL'] != 0,'temp'] = 0\n",
    "helpful['REVIEW_NEUTRAL'] = helpful['temp']\n",
    "del helpful['temp']\n",
    "helpful['B3_mul'] = np.log(data['reviewTextLength'])\n",
    "helpful['B4_mul'] = helpful['Review_Sentiment']*helpful['REVIEW_NEUTRAL']\n",
    "helpful['B5_mul'] = np.log(data['longetivity'])\n",
    "numerator = data['helpful'].str.split(':',n=1,expand=True)[0].astype(float)\n",
    "denominator = data['helpful'].str.split(':',n=1,expand=True)[1].astype(float)\n",
    "ratio=numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-33d291555d64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreg_for_helpful\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhelpful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "reg_for_helpful = LogisticRegression().fit(helpful, ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is for readership: [-0.01047036 -0.07413579  0.0048672   0.04432912  0.09628507  0.42113113]\n",
      "This is for helpfulness: [ 6.02118423e+11 -6.02118423e+11  9.90524292e-02 -1.00097656e-02\n",
      "  1.94293350e-01]\n"
     ]
    }
   ],
   "source": [
    "helpful['ratio'] = ratio\n",
    "reg_for_helpful.coef_\n",
    "print(\"This is for readership:\",reg_for_reader.coef_)\n",
    "print(\"This is for helpfulness:\",reg_for_helpful.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Hypothesis testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The internally computed table of expected frequencies has a zero element at (0, 689).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-055745ee8198>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhelpful\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'B4_mul'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m \u001b[0mchi2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdof\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchi2_contingency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m table2Df.loc['H8'] = pd.Series({\n\u001b[0;32m     67\u001b[0m     \u001b[1;34m'Hypothesized relationship'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;34m'Review sentiment × review neutral → helpfulness'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\scipy\\stats\\contingency.py\u001b[0m in \u001b[0;36mchi2_contingency\u001b[1;34m(observed, correction, lambda_)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mzeropos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpected\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         raise ValueError(\"The internally computed table of expected \"\n\u001b[1;32m--> 253\u001b[1;33m                          \"frequencies has a zero element at %s.\" % (zeropos,))\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;31m# The degrees of freedom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The internally computed table of expected frequencies has a zero element at (0, 689)."
     ]
    }
   ],
   "source": [
    "table2Df = pd.DataFrame(columns=['Hypothesized relationship', 'Estimates (Wald Chi-square)', 'Results'], \n",
    "                        index = ['H1','H2','H3','H4','H5','H6','H7','H8'])\n",
    "\n",
    "obs = np.array([data['longetivity'], data['readership']])\n",
    "chi2, p, dof, expected = chi2_contingency(obs)\n",
    "table2Df.loc['H1'] = pd.Series({\n",
    "    'Hypothesized relationship' : 'Longevity → readership',\n",
    "    'Estimates (Wald Chi-square)': str(reg_for_reader.coef_[5]) +'(' + str(chi2) + ')',\n",
    "    'Results':'lol'\n",
    "})\n",
    "\n",
    "obs = np.array([data['sentimentSummary'], data['readership']])\n",
    "chi2, p, dof, expected = chi2_contingency(obs)\n",
    "table2Df.loc['H2'] = pd.Series({\n",
    "    'Hypothesized relationship' : 'Title sentiment → readership',\n",
    "    'Estimates (Wald Chi-square)': str(reg_for_reader.coef_[0]) +'(' + str(chi2) + ')',\n",
    "    'Results':'lol'\n",
    "})\n",
    "\n",
    "obs = np.array([readerData['B4_mul'], data['readership']])\n",
    "chi2, p, dof, expected = chi2_contingency(obs)\n",
    "table2Df.loc['H3'] = pd.Series({\n",
    "    'Hypothesized relationship' : 'Title sentiment × title positive → readership',\n",
    "    'Estimates (Wald Chi-square)': str(reg_for_reader.coef_[3]) +'(' + str(chi2) + ')',\n",
    "    'Results':'lol'\n",
    "})\n",
    "\n",
    "obs = np.array([data['summaryLength'], data['readership']])\n",
    "chi2, p, dof, expected = chi2_contingency(obs)\n",
    "table2Df.loc['H4'] = pd.Series({\n",
    "    'Hypothesized relationship' : 'Title length → readership',\n",
    "    'Estimates (Wald Chi-square)': str(reg_for_reader.coef_[2]) +'(' + str(chi2) + ')',\n",
    "    'Results':'lol'\n",
    "})\n",
    "\n",
    "obs = np.array([data['reviewTextLength'], data['readership']])\n",
    "chi2, p, dof, expected = chi2_contingency(obs)\n",
    "table2Df.loc['H5'] = pd.Series({\n",
    "    'Hypothesized relationship' : 'Review length → readership',\n",
    "    'Estimates (Wald Chi-square)': str(reg_for_reader.coef_[4]) +'(' + str(chi2) + ')',\n",
    "    'Results':'lol'\n",
    "})\n",
    "\n",
    "obs = np.array([data['reviewTextLength'], ratio])\n",
    "chi2, p, dof, expected = chi2_contingency(obs)\n",
    "table2Df.loc['H6'] = pd.Series({\n",
    "    'Hypothesized relationship' : 'Review length → helpfulness',\n",
    "    'Estimates (Wald Chi-square)': str(reg_for_helpful.coef_[2]) +'(' + str(chi2) + ')',\n",
    "    'Results':'lol'\n",
    "})\n",
    "\n",
    "# this has error below\n",
    "obs = np.array([data['sentimentText'], ratio])\n",
    "chi2, p, dof, expected = chi2_contingency(obs)\n",
    "# till here\n",
    "table2Df.loc['H7'] = pd.Series({\n",
    "    'Hypothesized relationship' : 'Review sentiment → helpfulness',\n",
    "    'Estimates (Wald Chi-square)': str(reg_for_helpful.coef_[0]) +'(' + str(chi2) + ')',\n",
    "    'Results':'lol'\n",
    "})\n",
    "\n",
    "obs = np.array([helpful['B4_mul'], ratio])\n",
    "chi2, p, dof, expected = chi2_contingency(obs)\n",
    "table2Df.loc['H8'] = pd.Series({\n",
    "    'Hypothesized relationship' : 'Review sentiment × review neutral → helpfulness',\n",
    "    'Estimates (Wald Chi-square)': str(reg_for_helpful.coef_[3]) +'(' + str(chi2) + ')',\n",
    "    'Results':'lol'\n",
    "})\n",
    "\n",
    "\n",
    "table2Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewTextPositive</th>\n",
       "      <th>...</th>\n",
       "      <th>polarityText</th>\n",
       "      <th>polaritySummary</th>\n",
       "      <th>sentimentText</th>\n",
       "      <th>sentimentSummary</th>\n",
       "      <th>summaryLength</th>\n",
       "      <th>reviewTextLength</th>\n",
       "      <th>readership</th>\n",
       "      <th>longetivity</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>countOfReviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AVRFGGCCCR6QU</td>\n",
       "      <td>0972683275</td>\n",
       "      <td>\"Alberto Dieguez \"\"premiere purchaser of rando...</td>\n",
       "      <td>3:4</td>\n",
       "      <td>This wall mount does everything it's supposed ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Fairly good wall mount</td>\n",
       "      <td>1283126400</td>\n",
       "      <td>08 30, 2010</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>81.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3109.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A26QCCO0101CO1</td>\n",
       "      <td>0972683275</td>\n",
       "      <td>\"Amazon Customer \"\"jkhinch\"\"\"</td>\n",
       "      <td>7:9</td>\n",
       "      <td>I used this for my 47&amp;#34; Samsung. Its fit/fe...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Just what I'd hoped</td>\n",
       "      <td>1361404800</td>\n",
       "      <td>02 21, 2013</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2203.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>A3QH8VQDE7HZCR</td>\n",
       "      <td>0972683275</td>\n",
       "      <td>costaricachris</td>\n",
       "      <td>15:19</td>\n",
       "      <td>Quality was excellent. Instructions were clear...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Real value for the money</td>\n",
       "      <td>1286236800</td>\n",
       "      <td>10 5, 2010</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>64.0</td>\n",
       "      <td>19</td>\n",
       "      <td>3073.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>A38FGQVJM18OWV</td>\n",
       "      <td>0972683275</td>\n",
       "      <td>\"George S. Mitchell \"\"gsmitchell\"\"\"</td>\n",
       "      <td>8:18</td>\n",
       "      <td>I checked around Amazon as well as some other ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>What a piece of junk!</td>\n",
       "      <td>1291161600</td>\n",
       "      <td>12 1, 2010</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>138.0</td>\n",
       "      <td>18</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>A7R4R9THNELTP</td>\n",
       "      <td>0972683275</td>\n",
       "      <td>LG</td>\n",
       "      <td>14:19</td>\n",
       "      <td>\"I mounted this in my RV and it holds a 26\"\" L...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Excellent, at any price</td>\n",
       "      <td>1285804800</td>\n",
       "      <td>09 30, 2010</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>47.0</td>\n",
       "      <td>19</td>\n",
       "      <td>3078.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         reviewerID        asin  \\\n",
       "22    AVRFGGCCCR6QU  0972683275   \n",
       "26   A26QCCO0101CO1  0972683275   \n",
       "56   A3QH8VQDE7HZCR  0972683275   \n",
       "82   A38FGQVJM18OWV  0972683275   \n",
       "141   A7R4R9THNELTP  0972683275   \n",
       "\n",
       "                                          reviewerName helpful  \\\n",
       "22   \"Alberto Dieguez \"\"premiere purchaser of rando...     3:4   \n",
       "26                       \"Amazon Customer \"\"jkhinch\"\"\"     7:9   \n",
       "56                                      costaricachris   15:19   \n",
       "82                 \"George S. Mitchell \"\"gsmitchell\"\"\"    8:18   \n",
       "141                                                 LG   14:19   \n",
       "\n",
       "                                            reviewText  overall  \\\n",
       "22   This wall mount does everything it's supposed ...      4.0   \n",
       "26   I used this for my 47&#34; Samsung. Its fit/fe...      5.0   \n",
       "56   Quality was excellent. Instructions were clear...      5.0   \n",
       "82   I checked around Amazon as well as some other ...      1.0   \n",
       "141  \"I mounted this in my RV and it holds a 26\"\" L...      5.0   \n",
       "\n",
       "                      summary  unixReviewTime   reviewTime  \\\n",
       "22     Fairly good wall mount      1283126400  08 30, 2010   \n",
       "26        Just what I'd hoped      1361404800  02 21, 2013   \n",
       "56   Real value for the money      1286236800   10 5, 2010   \n",
       "82      What a piece of junk!      1291161600   12 1, 2010   \n",
       "141   Excellent, at any price      1285804800  09 30, 2010   \n",
       "\n",
       "     reviewTextPositive       ...        polarityText  polaritySummary  \\\n",
       "22                    1       ...                   0                1   \n",
       "26                    3       ...                   1                1   \n",
       "56                    4       ...                   3                1   \n",
       "82                    2       ...                   0               -1   \n",
       "141                   3       ...                   0                3   \n",
       "\n",
       "     sentimentText  sentimentSummary  summaryLength  reviewTextLength  \\\n",
       "22               0                 1              4              81.0   \n",
       "26               3                 1              4              79.0   \n",
       "56               3                 1              5              64.0   \n",
       "82               2                 1              5             138.0   \n",
       "141              4                 3              4              47.0   \n",
       "\n",
       "     readership  longetivity  helpful_votes  countOfReviews  \n",
       "22            4       3109.0            3.0             219  \n",
       "26            9       2203.0            7.0             219  \n",
       "56           19       3073.0           15.0             219  \n",
       "82           18       3016.0            8.0             219  \n",
       "141          19       3078.0           14.0             219  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs\n",
    "#### The below contains 4 graphs as in the paper \n",
    "\n",
    "- polartiyText : ReviewPolarity\n",
    "- sentimentText : ReviewSentiment\n",
    "- polaritySummmary : TitlePolarity\n",
    "- Title_Sentiment : TitleSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x='polarityText',data=data, kind='count', aspect=1.5)\n",
    "g = sns.catplot(x='sentimentText',data=data, kind='count', aspect=1.5)\n",
    "g = sns.catplot(x='polaritySummary',data=data, kind='count', aspect=1.5)\n",
    "g = sns.catplot(x='Title_Sentiment',data=readerData, kind='count', aspect=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 25,  75],\n",
       "       [100, 100]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "obs = np.array([[25, 75], [100, 100]])\n",
    "obs\n",
    "# chi2, p, dof, expected = chi2_contingency(obs)\n",
    "# print(chi2, p, dof, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22       0\n",
       "26       3\n",
       "56       3\n",
       "82       2\n",
       "141      4\n",
       "145      3\n",
       "155      2\n",
       "156      2\n",
       "167      5\n",
       "201      1\n",
       "211      3\n",
       "221      1\n",
       "223      3\n",
       "230      3\n",
       "232      3\n",
       "362      2\n",
       "363      4\n",
       "366      3\n",
       "369      5\n",
       "370      0\n",
       "376      5\n",
       "377      4\n",
       "378      5\n",
       "380      4\n",
       "382      4\n",
       "383      4\n",
       "384      4\n",
       "385      6\n",
       "387      6\n",
       "389      3\n",
       "        ..\n",
       "32854    2\n",
       "32931    3\n",
       "32940    3\n",
       "32950    2\n",
       "33107    2\n",
       "33146    3\n",
       "33218    3\n",
       "33222    0\n",
       "33232    1\n",
       "33344    0\n",
       "33348    1\n",
       "33351    0\n",
       "33403    1\n",
       "33460    2\n",
       "33487    3\n",
       "33493    2\n",
       "33506    3\n",
       "33854    3\n",
       "33869    1\n",
       "33906    5\n",
       "33914    5\n",
       "33923    3\n",
       "33941    3\n",
       "33963    1\n",
       "33998    0\n",
       "34000    2\n",
       "34022    2\n",
       "34113    2\n",
       "34160    2\n",
       "34199    2\n",
       "Name: Review_Sentiment, Length: 1521, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = [2, 5]\n",
    "# b = [7, 6]\n",
    "\n",
    "# obs = np.array([data['longetivity'], data['readership']])\n",
    "# # obs\n",
    "# chi2, p, dof, expected = chi2_contingency(obs)\n",
    "\n",
    "# obs = np.array([data['sentimentSummary'], data['readership']])\n",
    "# chi2, p, dof, expected = chi2_contingency(obs)\n",
    "# print(chi2, p, dof)\n",
    "helpful['Review_Sentiment']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
